# Hướng Dẫn: Tải Dữ liệu Lịch sử & Tự động hóa Hàng ngày

## Giới thiệu

Chúc mừng bạn đã thiết lập thành công các script để lấy dữ liệu từ Amazon! Giờ là lúc đưa chúng vào hoạt động. Hướng dẫn này sẽ chỉ cho bạn 3 bước cốt lõi:

1.  **Chuẩn bị Database:** Chạy các file migration SQL để tạo các bảng cần thiết và **cấp quyền truy cập** cho ứng dụng.
2.  **Tải Dữ liệu Lịch sử (Backfilling):** Chạy các script một lần để lấy dữ liệu từ 60-90 ngày qua, cung cấp ngữ cảnh cho các phân tích của bạn.
3.  **Tự động hóa Hàng ngày:** Thiết lập một "cron job" trên server để tự động lấy dữ liệu của ngày hôm qua, mỗi ngày, giữ cho database của bạn luôn mới.

---

## Yêu cầu

-   Bạn đã đăng nhập vào VPS của mình qua SSH.
-   Toàn bộ code dự án đã có trên VPS.
-   File `backend/.env` đã được cấu hình đầy đủ và chính xác.

---

## Phần 1: Chuẩn bị Cơ sở dữ liệu (Chạy Migrations)

Trước khi có thể lưu dữ liệu, chúng ta cần tạo các bảng tương ứng trong PostgreSQL và cấp quyền cho user của ứng dụng.

> **QUAN TRỌNG:** Nếu bạn đã chạy bước này trước đây và gặp lỗi "permission denied", hãy chạy lại các lệnh bên dưới. Các file migration đã được cập nhật để sửa lỗi này.

1.  **Mở file migration và cập nhật Tên User:**
    -   **Đây là bước quan trọng để tránh lỗi "permission denied".**
    -   Mở file `backend/migrations/003_add_sp_search_term_report_table.sql.txt` và `backend/migrations/004_add_sales_and_traffic_tables.sql.txt` trên VPS của bạn (ví dụ: dùng lệnh `nano <path_to_file>`).
    -   Ở cuối mỗi file, bạn sẽ thấy một dòng `GRANT ... TO yourdbuser;`.
    -   **Hãy thay thế `yourdbuser`** bằng giá trị `DB_USER` thực tế từ file `backend/.env` của bạn. Lưu lại các file.

2.  **Đăng nhập vào PostgreSQL:**
    -   Sử dụng lệnh sau để kết nối trực tiếp vào database của bạn với quyền quản trị.
        ```bash
        sudo -u postgres psql -d amazon_data_analyzer
        ```
    -   Dấu nhắc lệnh sẽ đổi thành `amazon_data_analyzer=#`.

3.  **Chạy file Migration cho Search Term Report:**
    -   Sử dụng lệnh `\i` của `psql` để thực thi một file. Hãy thay `/var/www/Ads-auto` bằng đường dẫn **CHÍNH XÁC** đến thư mục dự án của bạn.
        ```sql
        \i /var/www/Ads-auto/backend/migrations/003_add_sp_search_term_report_table.sql.txt
        ```
    -   Bạn sẽ thấy các thông báo như `CREATE TABLE` và `GRANT`, cho biết lệnh đã thành công.

4.  **Chạy file Migration cho Sales & Traffic Report:**
    -   Tương tự, chạy lệnh cho file thứ hai:
        ```sql
        \i /var/www/Ads-auto/backend/migrations/004_add_sales_and_traffic_tables.sql.txt
        ```

5.  **Thoát khỏi psql:**
    -   Gõ `\q` và nhấn Enter để quay lại terminal bình thường.

**Database của bạn giờ đã sẵn sàng để nhận dữ liệu!**

---

## Phần 2: Tải Dữ liệu Lịch sử (Backfilling)

Bây giờ chúng ta sẽ chạy các script để lấp đầy các bảng vừa tạo với dữ liệu từ 60 ngày qua.

**Quan trọng:** Hãy chạy các lệnh này bên trong thư mục gốc của dự án của bạn (ví dụ: `/var/www/Ads-auto`).

1.  **Di chuyển đến thư mục dự án:**
    ```bash
    cd /var/www/Ads-auto
    ```

2.  **Tải Dữ liệu Báo cáo Search Term:**
    -   Lệnh sau sẽ tải dữ liệu cho một khoảng thời gian cụ thể.
    -   Chúng ta sử dụng `npm run` để chạy script đã được định nghĩa trong `package.json`. Dấu `--` được dùng để truyền các tham số (ngày tháng) vào cho script.
    -   **Lưu ý:** API của Amazon có thể giới hạn số ngày. Nếu gặp lỗi, hãy thử với khoảng thời gian ngắn hơn (ví dụ: 1 tuần một).
        ```bash
        # Ví dụ: Tải dữ liệu từ ngày 5 tháng 8 đến ngày 4 tháng 9 năm 2024
        npm run fetch:sp-search-terms -- 2024-08-05 2024-09-04
        ```

3.  **Tải Dữ liệu Báo cáo Sales & Traffic:**
    -   Tương tự, chạy script thứ hai.
        ```bash
        # Ví dụ: Tải dữ liệu cho tháng 1 năm 2024
        npm run fetch:sales-traffic -- 2024-01-01 2024-01-31
        ```

Hãy lặp lại quá trình này với các khoảng thời gian khác nhau cho đến khi bạn có đủ dữ liệu lịch sử mình cần.

---

## Phần 3: Tự động hóa Lấy Dữ liệu Hàng ngày với Cron

Đây là bước thiết lập một lần và hệ thống sẽ tự chạy mãi mãi. Chúng ta sẽ tạo một "cron job", một tác vụ được lập lịch trên Linux, để tự động chạy các script mỗi ngày một lần vào lúc 3 giờ sáng để lấy dữ liệu của ngày hôm qua.

1.  **Mở trình chỉnh sửa Crontab:**
    ```bash
    crontab -e
    ```
    -   Nếu đây là lần đầu tiên, bạn có thể được yêu cầu chọn một trình soạn thảo. Hãy chọn `nano` (thường là lựa chọn dễ nhất).

2.  **Thêm các dòng Cron Job:**
    -   Di chuyển con trỏ xuống cuối file và dán hai dòng sau vào.
    -   **CỰC KỲ QUAN TRỌNG:** Hãy thay đổi `/var/www/Ads-auto` thành đường dẫn **CHÍNH XÁC** đến thư mục dự án của bạn trên VPS.
    -   **Giải thích:**
        -   `0 3 * * *`: Lập lịch chạy vào 3:00 AM mỗi ngày.
        -   `cd ...`: Di chuyển vào thư mục dự án trước khi chạy lệnh.
        -   `npm run ...`: Chạy script thông qua npm.
        -   `$(date ...)`: Tự động tạo ra ngày hôm qua theo định dạng YYYY-MM-DD.
        -   `>> ... 2>&1`: Ghi lại tất cả output (kể cả lỗi) vào một file log để bạn có thể kiểm tra sau này.
    -   **Lưu ý quan trọng về Môi trường Cron:** Đôi khi, môi trường mà cron chạy rất tối giản và không biết `node` hay `npm` ở đâu. Nếu cron job không chạy, bạn có thể cần thêm dòng `PATH` ở đầu file crontab của mình. Để tìm đường dẫn, chạy lệnh `which npm` trong terminal của bạn và copy kết quả.
        ```cron
        # Ví dụ: Thêm dòng này vào đầu file crontab nếu cần
        # PATH=/home/yourusername/.nvm/versions/node/v22.17.1/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
        ```

    ```cron
    # Tự động lấy báo cáo Sponsored Products Search Term hàng ngày lúc 3:00 AM
    0 3 * * * cd /var/www/Ads-auto && npm run fetch:sp-search-terms -- $(date -d "yesterday" +\%Y-\%m-\%d) $(date -d "yesterday" +\%Y-\%m-\%d) >> /var/www/Ads-auto/logs/fetch_sp_search_term.log 2>&1

    # Tự động lấy báo cáo Sales & Traffic hàng ngày lúc 3:05 AM
    5 3 * * * cd /var/www/Ads-auto && npm run fetch:sales-traffic -- $(date -d "yesterday" +\%Y-\%m-\%d) $(date -d "yesterday" +\%Y-\%m-\%d) >> /var/www/Ads-auto/logs/fetch_sales_traffic.log 2>&1
    ```

3.  **Lưu và Thoát:**
    -   Nhấn `Ctrl + X`, sau đó `Y`, và `Enter` để lưu lại.
    -   Bạn sẽ thấy thông báo `crontab: installing new crontab`.

4.  **Tạo thư mục Logs:**
    -   Cron job sẽ ghi log vào thư mục `logs`, chúng ta cần tạo nó.
    -   Từ thư mục gốc của dự án, chạy lệnh:
        ```bash
        mkdir -p logs
        ```

## Hoàn tất!

Hệ thống của bạn giờ đã được thiết lập hoàn chỉnh! Nó không chỉ chứa dữ liệu lịch sử mà còn sẽ tự động cập nhật dữ liệu mới mỗi ngày. Ngày mai, bạn có thể kiểm tra các file trong thư mục `logs` để xác nhận rằng các cron job đã chạy thành công.

---

## Xử lý sự cố (Troubleshooting)

### Lỗi: `permission denied for table ...`

- **Nguyên nhân:** Lỗi này xảy ra khi người dùng database được định nghĩa trong `backend/.env` (ví dụ: `yourdbuser`) không có quyền đọc/ghi trên bảng mà script đang cố gắng truy cập. Bảng này được tạo bởi người dùng `postgres` và cần được cấp quyền một cách rõ ràng.
- **Giải pháp:**
    1. Quay lại **Phần 1** của hướng dẫn này.
    2. Đảm bảo rằng bạn đã **thay thế `yourdbuser`** trong các file migration `.sql.txt` bằng đúng tên `DB_USER` từ file `.env` của bạn.
    3. **Chạy lại các lệnh `\i`** trong `psql`. Thao tác này an toàn để chạy lại và sẽ áp dụng các quyền còn thiếu.