# Hướng Dẫn: Tải Dữ liệu Lịch sử & Tự động hóa Hàng ngày

## Giới thiệu

Chúc mừng bạn đã thiết lập thành công các script để lấy dữ liệu từ Amazon! Giờ là lúc đưa chúng vào hoạt động. Hướng dẫn này sẽ chỉ cho bạn 3 bước cốt lõi:

1.  **Chuẩn bị Database:** Chạy các file migration SQL để tạo tất cả các bảng cần thiết và **cấp quyền truy cập** cho ứng dụng.
2.  **Tải Dữ liệu Lịch sử (Backfilling):** Chạy các script một lần để lấy dữ liệu từ 60-90 ngày qua, cung cấp ngữ cảnh cho các phân tích của bạn.
3.  **Tự động hóa Hàng ngày:** Thiết lập một "cron job" trên server để tự động lấy dữ liệu của ngày hôm qua, mỗi ngày, giữ cho database của bạn luôn mới.

---

## Yêu cầu

-   Bạn đã đăng nhập vào VPS của mình qua SSH.
-   Toàn bộ code dự án đã có trên VPS.
-   File `backend/.env` đã được cấu hình đầy đủ và chính xác.

---

## Phần 1: Chuẩn bị Cơ sở dữ liệu (Chạy Migrations)

Trước khi có thể lưu dữ liệu, chúng ta cần tạo các bảng tương ứng trong PostgreSQL và cấp quyền cho user của ứng dụng.

> **QUAN TRỌNG:** Các file migration đã được nâng cấp để **an toàn khi chạy lại**. Nếu bạn gặp lỗi liên quan đến bảng hoặc cột không tồn tại (ví dụ: `column "sales" does not exist`), chỉ cần chạy lại các lệnh `\i` dưới đây. Hệ thống sẽ tự động thêm các cột còn thiếu mà không xóa dữ liệu hiện có.

1.  **Đăng nhập vào PostgreSQL:**
    -   Sử dụng lệnh sau để kết nối trực tiếp vào database của bạn với quyền quản trị.
        ```bash
        sudo -u postgres psql -d amazon_data_analyzer
        ```
    -   Dấu nhắc lệnh sẽ đổi thành `amazon_data_analyzer=#`.

2.  **Chạy các file Migration cần thiết:**
    -   Sử dụng lệnh `\i` của `psql` để thực thi một file. Hãy thay `/var/www/Ads-auto` bằng đường dẫn **CHÍNH XÁC** đến thư mục dự án của bạn.
    -   Chạy lần lượt các lệnh sau theo đúng thứ tự:
        ```sql
        -- Bảng báo cáo Search Query Performance (Brand Analytics)
        \i /var/www/Ads-auto/migrations/001_add_query_performance_table.sql.txt

        -- Bảng báo cáo Sponsored Products Search Term
        \i /var/www/Ads-auto/migrations/003_add_sp_search_term_report_table.sql.txt

        -- Bảng báo cáo Sales & Traffic
        \i /var/www/Ads-auto/migrations/004_add_sales_and_traffic_tables.sql.txt

        -- Bảng hàng đợi yêu cầu báo cáo
        \i /var/www/Ads-auto/migrations/005_add_report_requests_table.sql.txt
        
        -- Các bảng cho hệ thống Tự động hóa
        \i /var/www/Ads-auto/migrations/006_add_automation_tables.sql.txt
        
        -- Bảng cho tính năng Tăng tốc Ngân sách
        \i /var/www/Ads-auto/migrations/007_add_budget_acceleration_tables.sql.txt

        -- Bảng báo cáo Sponsored Brands Search Term
        \i /var/www/Ads-auto/migrations/008_add_sb_search_term_report_table.sql.txt
        
        -- Bảng báo cáo Sponsored Display Targeting
        \i /var/www/Ads-auto/migrations/009_add_sd_targeting_report_table.sql.txt
        
        -- Bảng lưu trữ cuộc trò chuyện của AI Co-Pilot
        \i /var/www/Ads-auto/migrations/010_add_ai_copilot_conversations.sql.txt
        
        -- Bảng lưu trữ danh sách sản phẩm (Listing)
        \i /var/www/Ads-auto/migrations/011_add_product_listings_table.sql.txt
        
        -- Bảng cho tính năng Lập lịch Tạo Campaign
        \i /var/www/Ads-auto/migrations/012_add_campaign_creation_rules_table.sql.txt
        
        -- (MỚI) Bảng để quản lý và xoay vòng API key
        \i /var/www/Ads-auto/migrations/013_add_api_keys_table.sql.txt
        ```
    -   Bạn sẽ thấy các thông báo như `CREATE TABLE`, `ALTER TABLE`, và `GRANT`, cho biết lệnh đã thành công.

3.  **Thoát khỏi psql:**
    -   Gõ `\q` và nhấn Enter để quay lại terminal bình thường.

**Database của bạn giờ đã sẵn sàng để nhận dữ liệu!**

---

## Phần 2: (QUAN TRỌNG) Cấu hình Gemini API Keys

Với hệ thống xoay vòng key mới, bạn không cần phải thêm key vào database bằng SQL nữa. Thay vào đó, hãy làm theo các bước sau:

1.  **Mở file cấu hình môi trường:**
    ```bash
    nano backend/.env
    ```
2.  **Thêm danh sách key của bạn:**
    -   Tìm hoặc thêm biến `GEMINI_API_KEYS`.
    -   Dán tất cả các Gemini API key của bạn vào đây, cách nhau bởi dấu phẩy, **không có khoảng trắng**.
    -   Ví dụ:
        ```env
        GEMINI_API_KEYS=key_cua_ban_1,key_cua_ban_2,key_cua_ban_3
        ```
3.  **Lưu file và thoát.**
4.  **Khởi động lại backend:**
    ```bash
    pm2 restart ppc-auto-backend
    ```
    -   Khi server khởi động lại, nó sẽ tự động đọc các key này và đồng bộ chúng vào database cho bạn.

---

## Phần 3: Tải Dữ liệu Lịch sử (Backfilling)

Bây giờ chúng ta sẽ chạy các script để lấp đầy các bảng vừa tạo với dữ liệu.

**Quan trọng:** Hãy chạy các lệnh này bên trong thư mục gốc của dự án của bạn (ví dụ: `/var/www/Ads-auto`).

### 3.1. Di chuyển đến thư mục dự án
```bash
cd /var/www/Ads-auto
```

### 3.2. (MỚI) Tải Báo cáo Search Query Performance

Báo cáo này cung cấp dữ liệu hàng tuần từ Brand Analytics.

1.  **Cơ chế Lấy ASIN Tự động:**
    -   Script này **hoàn toàn tự động**. Nó sẽ kết nối vào database và lấy danh sách tất cả các ASIN duy nhất đã từng xuất hiện trong báo cáo **Sales & Traffic** (từ bảng `sales_and_traffic_by_asin`).
    -   **Yêu cầu:** Bạn **phải** chạy script tải báo cáo Sales & Traffic trước khi chạy script này để hệ thống có danh sách ASIN cần theo dõi.
2.  **Chạy script:**
    -   Cú pháp: `npm run fetch:query-performance -- <YEAR> <START_WEEK> <END_WEEK>`
    -   Ví dụ, để tải dữ liệu cho các tuần từ 20 đến 35 của năm 2024:
        ```bash
        npm run fetch:query-performance -- 2025 29 38
        ```

### 3.3. Tải Báo cáo Search Term & Targeting (SP, SB, SD) - Quy trình Hai Giai đoạn

Để tải dữ liệu lịch sử số lượng lớn một cách hiệu quả, chúng ta sử dụng quy trình hai giai đoạn đã được mô tả trong [Hướng dẫn 10](10.HIGH_VOLUME_DATA_FETCHING_GUIDE.md).

#### Giai đoạn 1: Gửi Yêu cầu Hàng loạt

Script này sẽ gửi yêu cầu tạo báo cáo cho mỗi ngày trong khoảng thời gian bạn chỉ định và lưu vào hàng đợi, nó chạy rất nhanh.

1.  **Bắt đầu một phiên `screen` để chạy ngầm:**
    ```bash
    screen -S backfill-requests
    ```
2.  Bên trong phiên `screen`, chạy các lệnh sau để yêu cầu báo cáo cho 60 ngày qua (thay đổi ngày tháng nếu cần):
    ```bash
    # Yêu cầu báo cáo Sponsored Products
    npm run request:sp-search-terms -- 2025-09-23 2025-09-23

    # Yêu cầu báo cáo Sponsored Brands
    npm run request:sb-search-terms -- 2025-09-19 2025-09-19

    # Yêu cầu báo cáo Sponsored Display
    npm run request:sd-targeting -- 2025-09-23 2025-09-23
    ```
3.  **Ngắt kết nối (Detach):** Nhấn tổ hợp phím **`Ctrl + A`**, sau đó nhấn phím **`d`**.
4.  **CHỜ ĐỢI:** Bạn cần **chờ ít nhất 1-2 tiếng** để Amazon xử lý và tạo các báo cáo này.

#### Giai đoạn 2: Xử lý các Báo cáo đang chờ

Sau khi chờ đủ lâu, script này sẽ kiểm tra hàng đợi, tìm các báo cáo đã hoàn thành, tải chúng về và lưu dữ liệu.

1.  **Chạy script xử lý:**
    ```bash
    npm run process:pending-reports
    ```
2.  Bạn có thể chạy lại lệnh này nhiều lần. Nó sẽ chỉ xử lý các báo cáo đã hoàn thành và bỏ qua những báo cáo vẫn đang được tạo. Để tự động hóa hoàn toàn, hãy xem Phần 4.

### 3.4. Tải Báo cáo Sales & Traffic

Báo cáo này vẫn sử dụng quy trình một giai đoạn.

1.  **Bắt đầu một phiên `screen` khác:**
    ```bash
    screen -S sales-traffic-backfill
    ```
2.  Bên trong phiên, chạy lệnh với khoảng thời gian bạn muốn (ví dụ 60 ngày):
    ```bash
    npm run fetch:sales-traffic -- 2024-07-15 2024-09-12
    ```
3.  **Ngắt kết nối (Detach):** Nhấn **`Ctrl + A`**, sau đó **`d`**.

---

## Phần 4: Tự động hóa Lấy Dữ liệu Hàng ngày với Cron

Đây là bước thiết lập một lần và hệ thống sẽ tự chạy mãi mãi.

1.  **Mở trình chỉnh sửa Crontab:**
    ```bash
    crontab -e
    ```
2.  **Thêm các dòng Cron Job:**
    -   Dán nội dung sau vào cuối file, **thay đổi `/var/www/Ads-auto`** và `PATH` cho đúng với hệ thống của bạn.

    ```cron
    # ---------------- CRONTAB EXAMPLE ----------------
    
    # Cung cấp đường dẫn đến Node.js/npm. THAY THẾ bằng kết quả từ lệnh `which npm`.
    PATH=/root/.nvm/versions/node/v22.17.1/bin:/usr/bin:/bin
    
    # Đặt múi giờ cho tất cả các cron job là UTC-7 (America/Phoenix).
    TZ=America/Phoenix

    # (MỚI) Tự động lấy báo cáo Search Query Performance hàng tuần, chạy vào mỗi Chủ Nhật lúc 12:30 AM
    30 0 * * 0 cd /var/www/Ads-auto && npm run fetch:query-performance -- $(date -d "last week" +\%Y) $(date -d "last week" +\%V) $(date -d "last week" +\%V) >> /var/www/Ads-auto/logs/cron_query_performance.log 2>&1

    # Giai đoạn 1: Yêu cầu báo cáo hàng ngày lúc 1:00 AM cho dữ liệu của ngày hôm qua
    0 1 * * * cd /var/www/Ads-auto && npm run request:sp-search-terms -- $(date -d "1 day ago" +\%Y-\%m-\%d) $(date -d "1 day ago" +\%Y-\%m-\%d) >> /var/www/Ads-auto/logs/cron_sp_search_term_request.log 2>&1
    5 1 * * * cd /var/www/Ads-auto && npm run request:sb-search-terms -- $(date -d "1 day ago" +\%Y-\%m-\%d) $(date -d "1 day ago" +\%Y-\%m-\%d) >> /var/www/Ads-auto/logs/cron_sb_search_term_request.log 2>&1
    8 1 * * * cd /var/www/Ads-auto && npm run request:sd-targeting -- $(date -d "1 day ago" +\%Y-\%m-\%d) $(date -d "1 day ago" +\%Y-\%m-\%d) >> /var/www/Ads-auto/logs/cron_sd_targeting_request.log 2>&1
    
    # Tự động lấy báo cáo Sales & Traffic hàng ngày lúc 1:10 AM cho dữ liệu của ngày hôm qua
    10 1 * * * cd /var/www/Ads-auto && npm run fetch:sales-traffic -- $(date -d "2 day ago" +\%Y-\%m-\%d) $(date -d "2 day ago" +\%Y-\%m-\%d) >> /var/www/Ads-auto/logs/cron_sales_traffic.log 2>&1
    
    # Giai đoạn 2: Tự động xử lý các báo cáo đang chờ trong hàng đợi mỗi 45 phút
    */45 * * * * cd /var/www/Ads-auto && npm run process:pending-reports >> /var/www/Ads-auto/logs/cron_process_pending_reports.log 2>&1

    # ---------------- END CRONTAB EXAMPLE ----------------
    ```

3.  **Lưu và Thoát:** Nhấn `Ctrl + X`, sau đó `Y`, và `Enter`.
4.  **Tạo thư mục Logs:** `mkdir -p logs`

## Hoàn tất!
Hệ thống của bạn giờ đã được thiết lập hoàn chỉnh! Nó không chỉ chứa dữ liệu lịch sử mà còn sẽ tự động cập nhật dữ liệu mới mỗi ngày/tuần.
